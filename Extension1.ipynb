{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:38:31.944035Z",
     "iopub.status.busy": "2025-02-14T10:38:31.943734Z",
     "iopub.status.idle": "2025-02-14T10:38:40.563836Z",
     "shell.execute_reply": "2025-02-14T10:38:40.562728Z",
     "shell.execute_reply.started": "2025-02-14T10:38:31.944007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pandas scikit-learn keybert transformers torch huggingface_hub keyphrase-vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:38:40.565165Z",
     "iopub.status.busy": "2025-02-14T10:38:40.564953Z",
     "iopub.status.idle": "2025-02-14T10:39:09.417745Z",
     "shell.execute_reply": "2025-02-14T10:39:09.416832Z",
     "shell.execute_reply.started": "2025-02-14T10:38:40.565146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import warnings\n",
    "import configparser\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "\n",
    "# Hugging Face imports\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# KeyBERT and Sentence Transformers imports\n",
    "from keybert import KeyBERT, KeyLLM\n",
    "from keybert.llm import TextGeneration\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:09.420163Z",
     "iopub.status.busy": "2025-02-14T10:39:09.419845Z",
     "iopub.status.idle": "2025-02-14T10:39:09.505104Z",
     "shell.execute_reply": "2025-02-14T10:39:09.504486Z",
     "shell.execute_reply.started": "2025-02-14T10:39:09.420140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Hugging Face Token\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config.ini')\n",
    "HF_TOKEN = config['hf_token']['access_token'] # For Hugging Face\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:09.506627Z",
     "iopub.status.busy": "2025-02-14T10:39:09.506356Z",
     "iopub.status.idle": "2025-02-14T10:39:09.509971Z",
     "shell.execute_reply": "2025-02-14T10:39:09.509231Z",
     "shell.execute_reply.started": "2025-02-14T10:39:09.506606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:09.511298Z",
     "iopub.status.busy": "2025-02-14T10:39:09.510941Z",
     "iopub.status.idle": "2025-02-14T10:39:09.690898Z",
     "shell.execute_reply": "2025-02-14T10:39:09.689738Z",
     "shell.execute_reply.started": "2025-02-14T10:39:09.511266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mdocsutf8\u001b[m\u001b[m     \u001b[1m\u001b[36mkeys\u001b[m\u001b[m         lan.txt      language.txt\n"
     ]
    }
   ],
   "source": [
    "!ls data/SemEval2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:09.693167Z",
     "iopub.status.busy": "2025-02-14T10:39:09.692903Z",
     "iopub.status.idle": "2025-02-14T10:39:09.697299Z",
     "shell.execute_reply": "2025-02-14T10:39:09.696254Z",
     "shell.execute_reply.started": "2025-02-14T10:39:09.693143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "root_doc= 'data/SemEval2017/docsutf8/'\n",
    "root_key= 'data/SemEval2017/keys/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:09.698742Z",
     "iopub.status.busy": "2025-02-14T10:39:09.698354Z",
     "iopub.status.idle": "2025-02-14T10:39:13.956938Z",
     "shell.execute_reply": "2025-02-14T10:39:13.955947Z",
     "shell.execute_reply.started": "2025-02-14T10:39:09.698706Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0370269304009062</td>\n",
       "      <td>The microwave background is not the only unive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0375960115005630</td>\n",
       "      <td>The systems in which the Stern–Gerlach force i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0301932215002037</td>\n",
       "      <td>There is also a lack of agreement as to what c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0032386109001463</td>\n",
       "      <td>When incompatible three component polymer chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0022311513010313</td>\n",
       "      <td>The four bounding PCM wastes, given in Table 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID                                               text\n",
       "0  S0370269304009062  The microwave background is not the only unive...\n",
       "1  S0375960115005630  The systems in which the Stern–Gerlach force i...\n",
       "2  S0301932215002037  There is also a lack of agreement as to what c...\n",
       "3  S0032386109001463  When incompatible three component polymer chai...\n",
       "4  S0022311513010313  The four bounding PCM wastes, given in Table 1..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creazione di una lista per salvare i dati\n",
    "data = []\n",
    "\n",
    "# Scansione della cartella per leggere i file .txt\n",
    "for filename in os.listdir(root_doc):\n",
    "    if filename.endswith(\".txt\"):  # Controlla che sia un file di testo\n",
    "        file_path = os.path.join(root_doc, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "        data.append({\"ID\": re.sub('.txt', '', filename), \"text\": content})\n",
    "\n",
    "# Creazione del DataFrame\n",
    "doc_df = pd.DataFrame(data)\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:13.960353Z",
     "iopub.status.busy": "2025-02-14T10:39:13.960028Z",
     "iopub.status.idle": "2025-02-14T10:39:18.093858Z",
     "shell.execute_reply": "2025-02-14T10:39:18.093154Z",
     "shell.execute_reply.started": "2025-02-14T10:39:13.960326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0963869514001066</td>\n",
       "      <td>conventional TFM\\ndiscretely sampled\\ndiscreti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0167931713002438</td>\n",
       "      <td>a-SiO2\\na-SiO2 leading\\nbulk\\ndeep electron tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0963869514001078</td>\n",
       "      <td>electromagnetic ultrasound generation\\nEMATs\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0038092X14000942</td>\n",
       "      <td>ambient temperature\\ndirect solar radiation in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0304399111001811</td>\n",
       "      <td>angular divergence\\naperture\\ncreation of nm-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID                                               keys\n",
       "0  S0963869514001066  conventional TFM\\ndiscretely sampled\\ndiscreti...\n",
       "1  S0167931713002438  a-SiO2\\na-SiO2 leading\\nbulk\\ndeep electron tr...\n",
       "2  S0963869514001078  electromagnetic ultrasound generation\\nEMATs\\n...\n",
       "3  S0038092X14000942  ambient temperature\\ndirect solar radiation in...\n",
       "4  S0304399111001811  angular divergence\\naperture\\ncreation of nm-s..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creazione di una lista per salvare i dati\n",
    "data = []\n",
    "\n",
    "# Scansione della cartella per leggere i file .txt\n",
    "for filename in os.listdir(root_key):\n",
    "    if filename.endswith(\".key\"):  # Controlla che sia un file di testo\n",
    "        file_path = os.path.join(root_key, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read() # sep '\\n'\n",
    "        data.append({\"ID\": re.sub('.key', '', filename), \"keys\": content})\n",
    "\n",
    "# Creazione del DataFrame\n",
    "key_df = pd.DataFrame(data)\n",
    "key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:18.095240Z",
     "iopub.status.busy": "2025-02-14T10:39:18.094939Z",
     "iopub.status.idle": "2025-02-14T10:39:18.119404Z",
     "shell.execute_reply": "2025-02-14T10:39:18.118580Z",
     "shell.execute_reply.started": "2025-02-14T10:39:18.095216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0370269304009062</td>\n",
       "      <td>The microwave background is not the only unive...</td>\n",
       "      <td>cosmological evolution of UHECR injection\\nflu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0375960115005630</td>\n",
       "      <td>The systems in which the Stern–Gerlach force i...</td>\n",
       "      <td>density waves\\nelectromagnetic field\\nelectrom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0301932215002037</td>\n",
       "      <td>There is also a lack of agreement as to what c...</td>\n",
       "      <td>churn\\nchurn flow\\ndisturbance waves\\nfrequenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0032386109001463</td>\n",
       "      <td>When incompatible three component polymer chai...</td>\n",
       "      <td>chain entropy\\ncylinders\\ndiagonal bond method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0022311513010313</td>\n",
       "      <td>The four bounding PCM wastes, given in Table 1...</td>\n",
       "      <td>aluminium\\nblast-furnace slag “Calumite”\\nboun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID                                               text  \\\n",
       "0  S0370269304009062  The microwave background is not the only unive...   \n",
       "1  S0375960115005630  The systems in which the Stern–Gerlach force i...   \n",
       "2  S0301932215002037  There is also a lack of agreement as to what c...   \n",
       "3  S0032386109001463  When incompatible three component polymer chai...   \n",
       "4  S0022311513010313  The four bounding PCM wastes, given in Table 1...   \n",
       "\n",
       "                                                keys  \n",
       "0  cosmological evolution of UHECR injection\\nflu...  \n",
       "1  density waves\\nelectromagnetic field\\nelectrom...  \n",
       "2  churn\\nchurn flow\\ndisturbance waves\\nfrequenc...  \n",
       "3  chain entropy\\ncylinders\\ndiagonal bond method...  \n",
       "4  aluminium\\nblast-furnace slag “Calumite”\\nboun...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_eval_df = pd.merge(doc_df, key_df, on=\"ID\")\n",
    "sem_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different KeyWords approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:18.120601Z",
     "iopub.status.busy": "2025-02-14T10:39:18.120306Z",
     "iopub.status.idle": "2025-02-14T10:39:18.155889Z",
     "shell.execute_reply": "2025-02-14T10:39:18.154997Z",
     "shell.execute_reply.started": "2025-02-14T10:39:18.120580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred_kw, true_kw):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1-score for keyword/keyphrase extraction.\n",
    "\n",
    "    Args:\n",
    "        pred_kw (list of list): Nested lists with predicted keywords/keyphrases.\n",
    "        true_kw (list of list): Nested lists with true keywords/keyphrases.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with evaluation metrics (precision, recall, F1-score).\n",
    "    \"\"\"\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "\n",
    "    for pred, true in zip(pred_kw, true_kw):\n",
    "        pred_set, true_set = set(pred), set(true)  # Convert to sets\n",
    "\n",
    "        # Create binary vectors for sklearn\n",
    "        all_keywords = list(true_set | pred_set)  # Union of all keywords\n",
    "        y_true = [1 if kw in true_set else 0 for kw in all_keywords]\n",
    "        y_pred = [1 if kw in pred_set else 0 for kw in all_keywords]\n",
    "\n",
    "        # Calculate metrics with sklearn\n",
    "        precision_list.append(precision_score(y_true, y_pred, zero_division=0))\n",
    "        recall_list.append(recall_score(y_true, y_pred, zero_division=0))\n",
    "        f1_list.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    # Average the metrics\n",
    "    eval_dict = {\n",
    "        \"precision\": sum(precision_list) / len(precision_list),\n",
    "        \"recall\": sum(recall_list) / len(recall_list),\n",
    "        \"f1_score\": sum(f1_list) / len(f1_list),\n",
    "    }\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:18.173382Z",
     "iopub.status.busy": "2025-02-14T10:39:18.173045Z",
     "iopub.status.idle": "2025-02-14T10:39:18.187405Z",
     "shell.execute_reply": "2025-02-14T10:39:18.186724Z",
     "shell.execute_reply.started": "2025-02-14T10:39:18.173338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "KEY_LLM_PROMPT = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "\n",
    "You are a helpful assistant specialized in extracting comma-separated keywords.\n",
    "You are to the point and only give the answer in isolation without any chat-based fluff.\n",
    "\n",
    "<</SYS>>\n",
    "I have the following document:\n",
    "- The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken [INST]\n",
    "\n",
    "I have the following document:\n",
    "- [DOCUMENT]\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "def initialize_models(embedding_model='all-MiniLM-L6-v2', llm_model='gpt-2', use_keyllm=True):\n",
    "    \"\"\"\n",
    "    Loads and initializes machine learning models for embeddings, keyword extraction, text generation, \n",
    "    question answering, and summarization, using GPU if available.\n",
    "\n",
    "    Args:\n",
    "        embedding_model (str): Model for sentence embeddings. Defaults to 'all-MiniLM-L6-v2'.\n",
    "        llm_model (str): Model for text generation. Defaults to 'gpt-2'.\n",
    "        qa_model (str): Model for question answering. Defaults to 'distilbert-base-cased-distilled-squad'.\n",
    "        sum_model (str): Model for summarization. Defaults to 'facebook/bart-large-cnn'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Initialized models:\n",
    "            - SentenceTransformer for embeddings.\n",
    "            - KeyBERT for keyword extraction.\n",
    "            - KeyLLM for LLM-based keyword extraction.\n",
    "            - HuggingFace pipelines for question answering and summarization.\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        # Initialize the sentence transformer model\n",
    "        print(\"Loading Sentence Transformer model...\")\n",
    "        model = SentenceTransformer(embedding_model, device=device)\n",
    "        \n",
    "        # Initialize the KeyBERT model\n",
    "        print(\"Loading KeyBERT model...\")\n",
    "        kw_bert_model = KeyBERT(model)\n",
    "        \n",
    "        # Initialize the KeyLLM model\n",
    "        if use_keyllm:\n",
    "            print(\"Loading KeyLLM model...\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(llm_model)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "                llm_model,\n",
    "                trust_remote_code=True,\n",
    "                device_map='auto'\n",
    "            )\n",
    "            generator = pipeline(\n",
    "                model=llm_model, tokenizer=tokenizer,\n",
    "                task='text-generation',\n",
    "                max_new_tokens=50,\n",
    "                repetition_penalty=1.1,\n",
    "                model_kwargs={\"load_in_4bit\": True}\n",
    "            )\n",
    "            llm = TextGeneration(generator, prompt=KEY_LLM_PROMPT)  # KEYLLM_PROMPT global variable\n",
    "            kw_llm_model = KeyLLM(llm)\n",
    "        else:\n",
    "            kw_llm_model = None\n",
    "        \n",
    "        print(\"Models loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the models: {e}\")\n",
    "    \n",
    "    return model, kw_bert_model, kw_llm_model\n",
    "\n",
    "\n",
    "def extract_keywords_from_text(docs, kw_bert_model, kw_llm_model, use_keyllm, diversity, top_n):\n",
    "    \"\"\"\n",
    "    Extracts keywords from the input document(s) using either KeyBERT or a combination of KeyBERT and KeyLLM.\n",
    "\n",
    "    Args:\n",
    "        docs (str or list): The input text(s) to process.\n",
    "        kw_bert_model (KeyBERT): A KeyBERT model for keyword extraction.\n",
    "        kw_llm_model (KeyLLM): A KeyLLM model for refining keywords (used if `use_keyllm` is True).\n",
    "        use_keyllm (bool): If True, uses KeyLLM to refine the keywords extracted by KeyBERT.\n",
    "        diversity (float): Diversity parameter for MMR to ensure varied keywords.\n",
    "        top_n (int): Number of top keywords to return.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted keywords.\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_keyllm:\n",
    "        # Extract initial keywords with KeyBERT (limit to 20 for LLM processing)\n",
    "        initial_keywords = kw_bert_model.extract_keywords(\n",
    "            docs=docs, \n",
    "            vectorizer=KeyphraseCountVectorizer(), \n",
    "            use_mmr=True, \n",
    "            diversity=diversity, \n",
    "            top_n=20\n",
    "        )\n",
    "        \n",
    "        # Refine the keywords using KeyLLM\n",
    "        refined_keywords = kw_llm_model.extract_keywords(docs=docs, candidate_keywords=initial_keywords)\n",
    "        initial_keywords = [key[0] for key in initial_keywords]\n",
    "        \n",
    "        # Concatenation candidates from KeyBert and KeyLLM\n",
    "        final_candidates = list(set(initial_keywords) | set(refined_keywords[0])) \n",
    "\n",
    "        # Re-rank the refined keywords and select the top_n with KeyBERT\n",
    "        keywords_list = kw_bert_model.extract_keywords(\n",
    "            docs=docs, \n",
    "            candidates=final_candidates,\n",
    "            use_mmr=True, \n",
    "            diversity=diversity, \n",
    "            top_n=top_n # < 20\n",
    "        )\n",
    "    else:\n",
    "        # Directly extract the top_n keywords using KeyBERT\n",
    "        keywords_list = kw_bert_model.extract_keywords(\n",
    "            docs=docs, \n",
    "            vectorizer=KeyphraseCountVectorizer(), \n",
    "            use_mmr=False, #True\n",
    "            diversity=diversity, \n",
    "            top_n=top_n\n",
    "        )\n",
    "    keywords_list = [key[0] for key in keywords_list]\n",
    "    return keywords_list\n",
    "\n",
    "\n",
    "def test_keywords_extraction(kw_bert_model, kw_llm_model, texts, true_kw, use_keyllm, diversity, top_n):\n",
    "    \"\"\"\n",
    "    Tests keyword extraction with KeyBERT or KeyBERT + LLM, calculating execution time and metrics.\n",
    "\n",
    "    Args:\n",
    "        kw_bert_model: KeyBERT model for keyword extraction.\n",
    "        kw_llm_model: LLM model for refining keywords (used only if use_keyllm=True).\n",
    "        texts (list of str): List of texts to process.\n",
    "        true_kw (list of list): List of reference keywords.\n",
    "        use_keyllm (bool): If True, use KeyBERT + LLM. If False, use only KeyBERT.\n",
    "        diversity (float): Diversity parameter for MMR.\n",
    "        top_n (int): Maximum number of keywords to extract per text.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with execution time and precision, recall, and F1-score metrics.\n",
    "    \"\"\"\n",
    "    pred_kw = []\n",
    "    start_time = time.time()  # Start time measurement\n",
    "\n",
    "    # Generate keywords for each text\n",
    "    for text in tqdm(texts, desc=\"Processing texts\"):\n",
    "        keywords_list = extract_keywords_from_text(text, kw_bert_model, kw_llm_model, use_keyllm, diversity, top_n)\n",
    "        pred_kw.append(keywords_list)\n",
    "\n",
    "    end_time = time.time()  # End time measurement\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    eval_metrics = compute_metrics(pred_kw, true_kw)\n",
    "    eval_metrics[\"execution_time\"] = end_time - start_time\n",
    "\n",
    "    return eval_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:18.188544Z",
     "iopub.status.busy": "2025-02-14T10:39:18.188280Z",
     "iopub.status.idle": "2025-02-14T10:39:18.202067Z",
     "shell.execute_reply": "2025-02-14T10:39:18.201191Z",
     "shell.execute_reply.started": "2025-02-14T10:39:18.188513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def grid_search_extraction(param_combinations, texts, true_kw):\n",
    "    \"\"\"\n",
    "    Performs a Grid Search to test different parameter combinations\n",
    "    in the test_extraction function, freeing GPU memory between iterations.\n",
    "\n",
    "    Args:\n",
    "        param_combinations (list of tuples): List with all parameter combinations.\n",
    "        texts (list of str): List of texts to process.\n",
    "        true_kw (list of list): List of reference keywords.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with metric results for each combination.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Test each parameter combination\n",
    "    for embedding_model, llm_model, use_keyllm, diversity, top_n in tqdm(param_combinations, desc=\"Processing parameter combinations\"):\n",
    "\n",
    "        print(f\"Testing: emb_model={embedding_model}, llm_model={llm_model}, use_keyllm={use_keyllm}, diversity={diversity}, top_n={top_n}\")\n",
    "\n",
    "        # Initialize the KeyBERT model with the specified embedding model\n",
    "        _, kw_bert_model, kw_llm_model = initialize_models(embedding_model, llm_model, use_keyllm)\n",
    "\n",
    "        # Start the test with the current parameters\n",
    "        metrics = test_keywords_extraction(\n",
    "            kw_bert_model, kw_llm_model, texts, true_kw,\n",
    "            use_keyllm=use_keyllm, diversity=diversity, top_n=top_n\n",
    "        )\n",
    "\n",
    "        # Save the results in a list\n",
    "        results.append({\n",
    "            \"embedding_model\": embedding_model,\n",
    "            \"llm_model\": llm_model,\n",
    "            \"use_keyllm\": use_keyllm,\n",
    "            \"diversity\": diversity,\n",
    "            \"top_n\": top_n,\n",
    "            \"precision\": metrics[\"precision\"],\n",
    "            \"recall\": metrics[\"recall\"],\n",
    "            \"f1_score\": metrics[\"f1_score\"],\n",
    "            \"execution_time\": metrics[\"execution_time\"]\n",
    "        })\n",
    "\n",
    "        del kw_bert_model\n",
    "        del kw_llm_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Convert the results to a DataFrame for easier analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:18.203340Z",
     "iopub.status.busy": "2025-02-14T10:39:18.203019Z",
     "iopub.status.idle": "2025-02-14T10:39:18.217612Z",
     "shell.execute_reply": "2025-02-14T10:39:18.216704Z",
     "shell.execute_reply.started": "2025-02-14T10:39:18.203311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters for Grid Search\n",
    "param_grid = {\n",
    "    \"embedding_model\": [\"all-MiniLM-L6-v2\"],#, \"paraphrase-MiniLM-L12-v2\"],  # KeyBERT embedding models\n",
    "    \"llm_model\": [\"meta-llama/Llama-3.2-3B\"],  # LLM models for KeyLLM\n",
    "    \"use_keyllm\": [True, False],  # Test both KeyBERT and KeyBERT + LLM\n",
    "    \"diversity\": [0.3, 0.5, 0.7],  # Variation of the MMR parameter\n",
    "    \"top_n\": [3, 5, 10]  # Maximum number of extracted keywords\n",
    "}\n",
    "\n",
    "# Generate all possible parameter combinations\n",
    "param_combinations = list(itertools.product(\n",
    "    param_grid[\"embedding_model\"],\n",
    "    param_grid[\"llm_model\"],\n",
    "    param_grid[\"use_keyllm\"],\n",
    "    param_grid[\"diversity\"],\n",
    "    param_grid[\"top_n\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:39:23.421288Z",
     "iopub.status.busy": "2025-02-14T10:39:23.420979Z",
     "iopub.status.idle": "2025-02-14T11:09:56.969043Z",
     "shell.execute_reply": "2025-02-14T11:09:56.968011Z",
     "shell.execute_reply.started": "2025-02-14T10:39:23.421264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "texts = sem_eval_df[\"text\"].tolist()\n",
    "true_kw = sem_eval_df[\"keys\"].str.split(\"\\n\").tolist()\n",
    "\n",
    "# Test della funzione grid_search_extraction\n",
    "results_df = grid_search_extraction(param_combinations, texts, true_kw)\n",
    "print(\"Grid Search Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pick the best model\n",
    "best_f1_params = results_df.iloc[results_df[\"f1_score\"].idxmax()]\n",
    "best_precision_params = results_df.iloc[results_df[\"precision\"].idxmax()]\n",
    "best_recall_params = results_df.iloc[results_df[\"recall\"].idxmax()]\n",
    "\n",
    "# print the best model parameters\n",
    "print(\"Best F1 Score Parameters:\")\n",
    "print(best_f1_params)\n",
    "print(\"\\nBest Precision Parameters:\")\n",
    "print(best_precision_params)\n",
    "print(\"\\nBest Recall Parameters:\")\n",
    "print(best_recall_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6646477,
     "sourceId": 10721994,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venvDNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
